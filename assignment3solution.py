# -*- coding: utf-8 -*-
"""Assignment3Solution

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18mJWpYd64x5b34Gj6V47P7VE2Ike9Ozf

**Task a) Load and Prepare Data
Load CIFAR-20 Data**: Use keras.datasets.cifar100 with "coarse" labels.
Convert to Grayscale: Average RGB values.
Prepare Stratified Validation Set: Use train_test_split from sklearn with stratification on labels.
"""

import numpy as np
import tensorflow.keras.datasets as tfd
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical

# Load CIFAR-20 dataset
(train_data, test_data) = tfd.cifar100.load_data(label_mode="coarse")
(x_train, y_train), (x_test, y_test) = train_data, test_data

# Convert to grayscale
x_train = np.mean(x_train, axis=3, keepdims=True) / 255.0
x_test = np.mean(x_test, axis=3, keepdims=True) / 255.0

# Convert labels to one-hot encoding
y_train = to_categorical(y_train, 20)
y_test = to_categorical(y_test, 20)

# Create stratified validation set
x_train, x_val, y_train, y_val = train_test_split(
    x_train, y_train, test_size=0.2, stratify=y_train.argmax(axis=1), random_state=42
)

"""**Task b) Design and Train Customized CNN**

1.  Architecture Variations: Experiment with depth (convolutional layers) and width (number of filters).
2.  Loss Function: Use categorical_crossentropy since this is multi-class classification.

3.   Early Stopping: Monitor validation loss to prevent overfitting.

"""

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
import pandas as pd

# Define CNN architectures
def create_model(depth, filters, dropout_rate=0.5):
    model = Sequential()
    model.add(tf.keras.layers.Input(shape=(32, 32, 1)))  # Define input shape here
    for _ in range(depth):
        model.add(Conv2D(filters, (3, 3), activation='relu', padding='same'))
        model.add(MaxPooling2D((2, 2)))
    model.add(Flatten())
    model.add(Dense(128, activation='relu'))
    model.add(Dropout(dropout_rate))
    model.add(Dense(20, activation='softmax'))  # 20 classes
    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )
    return model

# Train and evaluate different architectures
results = []
depths = [2, 3, 4]  # Vary depth
filters = [32, 64]  # Vary width

for d in depths:
    for f in filters:
        model = create_model(d, f)
        history = model.fit(
            x_train, y_train, epochs=20, batch_size=64,
            validation_data=(x_val, y_val), callbacks=[tf.keras.callbacks.EarlyStopping(patience=3)]
        )
        results.append({
            'depth': d,
            'filters': f,
            'train_acc': max(history.history['accuracy']),
            'val_acc': max(history.history['val_accuracy'])
        })



# Create DataFrame from results
results_df = pd.DataFrame(results)
print("Architectures Performance:")
print(results_df)

# Save to CSV (optional)
results_df.to_csv("architectures_performance.csv", index=False)

"""**Task c) Compare Regularization**
Test L2 regularization and dropout rates.
"""

from tensorflow.keras.regularizers import l2

# Modify model creation for L2
def create_model_with_l2(depth, filters, l2_rate=0.01, dropout_rate=0.5):
    model = Sequential()
    model.add(tf.keras.layers.Input(shape=(32, 32, 1)))
    for _ in range(depth):
        model.add(Conv2D(filters, (3, 3), activation='relu', padding='same',
                         kernel_regularizer=l2(l2_rate)))
        model.add(MaxPooling2D((2, 2)))
    model.add(Flatten())
    model.add(Dense(128, activation='relu', kernel_regularizer=l2(l2_rate)))
    model.add(Dropout(dropout_rate))
    model.add(Dense(20, activation='softmax'))  # 20 classes
    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )
    return model

# Test different regularization
l2_rates = [0.001, 0.01]
dropout_rates = [0.3, 0.5]

reg_results = []
for l2_rate in l2_rates:
    for dropout_rate in dropout_rates:
        model = create_model_with_l2(3, 64, l2_rate, dropout_rate)
        history = model.fit(
            x_train, y_train, epochs=20, batch_size=64,
            validation_data=(x_val, y_val), callbacks=[tf.keras.callbacks.EarlyStopping(patience=3)]
        )
        reg_results.append({
            'l2_rate': l2_rate,
            'dropout_rate': dropout_rate,
            'train_acc': max(history.history['accuracy']),
            'val_acc': max(history.history['val_accuracy'])
        })

# Create DataFrame for regularization results
reg_results_df = pd.DataFrame(reg_results)
print("Regularization Performance:")
print(reg_results_df)

# Save to CSV (optional)
reg_results_df.to_csv("regularization_performance.csv", index=False)

"""**Part d) Final Model Training and Architecture Summary**
Here, I finalize the architecture based on the best results from parts b and c.

Final Model Architecture:
Depth: 3 Conv Layers
Width: 64 Filters
Regularization: L2 (0.001) and Dropout (0.3)
Optimizer: Adam with learning rate 0.001
Epochs: 20 with early stopping
Batch Size: 64
"""

# Final model architecture
final_model = create_model_with_l2(depth=3, filters=64, l2_rate=0.001, dropout_rate=0.3)

# Train on full training set
final_history = final_model.fit(
    x_train, y_train, epochs=20, batch_size=64,
    validation_data=(x_val, y_val), callbacks=[tf.keras.callbacks.EarlyStopping(patience=3)]
)

# Save final model
final_model.save("final_cnn_model.keras")

# Plot training and validation loss
import matplotlib.pyplot as plt

plt.plot(final_history.history['loss'], label='Training Loss')
plt.plot(final_history.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Evaluate on test set
test_loss, test_accuracy = final_model.evaluate(x_test, y_test, verbose=0)
print(f"Final Test Accuracy: {test_accuracy:.2%}")

# Confusion matrix
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

y_pred = final_model.predict(x_test).argmax(axis=1)
y_true = y_test.argmax(axis=1)

cm = confusion_matrix(y_true, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=range(20))
disp.plot(cmap=plt.cm.Blues)
plt.title("Confusion Matrix")
plt.show()

"""**Part e) Evaluation on Perturbed Dataset**

Load Perturbed Test Set: Use provided .pkl file.

Apply Model Modifications:
Batch Normalization
Residual Connections
Data Augmentation
Larger Filters
Deeper Networ

**Compare Results:** I Create a table to showing accuracies on training, test, and perturbed datasets.
"""

# Load perturbed dataset
import pickle

dict = pickle.load(open('/content/cifar20_perturb_test.pkl', 'rb'))
x_perturb, y_perturb = dict['x_perturb'], dict['y_perturb']

# Convert to grayscale
x_perturb = np.mean(x_perturb, axis=3, keepdims=True) / 255.0
y_perturb = to_categorical(y_perturb, 20)

# Evaluate final model on perturbed test set
perturb_loss, perturb_accuracy = final_model.evaluate(x_perturb, y_perturb, verbose=0)
print(f"Final Perturbed Test Accuracy: {perturb_accuracy:.2%}")

# Experiment with modifications
modifications_results = []

# 1. Batch Normalization
def create_model_with_bn(depth, filters):
    model = Sequential()
    for _ in range(depth):
        model.add(Conv2D(filters, (3, 3), activation='relu', padding='same'))
        model.add(tf.keras.layers.BatchNormalization())
        model.add(MaxPooling2D((2, 2)))
    model.add(Flatten())
    model.add(Dense(128, activation='relu'))
    model.add(Dropout(0.3))
    model.add(Dense(20, activation='softmax'))
    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )
    return model

# Train and evaluate modified models
for mod_name, model_fn in [("BatchNorm", create_model_with_bn)]:
    modified_model = model_fn(depth=3, filters=64)
    modified_model.fit(x_train, y_train, epochs=10, batch_size=64, verbose=0)
    train_acc = modified_model.evaluate(x_train, y_train, verbose=0)[1]
    test_acc = modified_model.evaluate(x_test, y_test, verbose=0)[1]
    perturb_acc = modified_model.evaluate(x_perturb, y_perturb, verbose=0)[1]
    modifications_results.append({
        "Modification": mod_name,
        "Train Acc": train_acc,
        "Test Acc": test_acc,
        "Perturbed Acc": perturb_acc
    })

# Results Table
modifications_df = pd.DataFrame(modifications_results)
print("Modifications Performance:")
print(modifications_df)